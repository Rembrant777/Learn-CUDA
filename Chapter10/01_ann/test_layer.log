Running main() from /home/raytrack/workspace/Learn-CUDA/Chapter10/googletest/googletest/src/gtest_main.cc
[==========] Running 6 tests from 2 test suites.
[----------] Global test environment set-up.
[----------] 3 tests from TestLayer
[ RUN      ] TestLayer.DenseLayerCreateTest
[       OK ] TestLayer.DenseLayerCreateTest (0 ms)
[ RUN      ] TestLayer.ActivationLayerCreateTest
[       OK ] TestLayer.ActivationLayerCreateTest (0 ms)
[ RUN      ] TestLayer.SoftmaxLayerCreateTest
[       OK ] TestLayer.SoftmaxLayerCreateTest (477 ms)
[----------] 3 tests from TestLayer (477 ms total)

[----------] 3 tests from Testlayer
[ RUN      ] Testlayer.DenseInitWeightBias
.. initialized dense-layer-0 layer ..
**bias-value	: (8) 	.n: 1, .c: 1, .h: 8, .w: 1	(h:0x178f1e0, d:0x7fdb1c600600)
<---- batch [0] ----->
	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	
<---- batch [1] ----->
	0.000000	0.000000	0.000000	0.000000	88.491394	0.000000	88.491394	0.000000	
<---- batch [2] ----->
	0.000000	0.000000	0.000000	-nan	0.000000	0.000000	0.000000	0.000000	
<---- batch [3] ----->
	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	
**weight-value	: (192) 	.n: 1, .c: 1, .h: 24, .w: 8	(h:0x178ee60, d:0x7fdb1c600200)
<---- batch [0] ----->
	0.497185	0.432557	-0.371876	0.499041	-0.263911	-0.103419	-0.112089	0.169746	0.435539	0.346311	-0.186726	0.024548	-0.056547	-0.270423	0.034414	0.413962	
	-0.042795	-0.069301	0.439128	0.278389	0.215971	0.302758	-0.407199	0.018153	0.365020	0.329147	0.329603	-0.226950	-0.440757	0.170528	0.093066	0.171654	
	-0.088212	-0.302449	-0.210370	-0.357880	0.283314	-0.087461	-0.465829	0.124030	0.160636	-0.201505	-0.053865	-0.277875	-0.426636	-0.030761	-0.403828	0.403370	
	-0.380510	0.024799	-0.416377	0.416861	0.410448	-0.201070	0.084389	0.065912	0.113938	0.456536	-0.239021	-0.268985	0.033448	0.449938	-0.006940	0.040601	
<---- batch [1] ----->
	0.000000	0.000000	0.000000	0.000000	88.490234	0.000000	88.491638	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	
	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	
	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	88.491394	0.000000	88.491394	0.000000	
	0.000000	0.000000	0.000000	-nan	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	
<---- batch [2] ----->
	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	16.807037	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	
	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	
	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	
	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	
<---- batch [3] ----->
	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	
	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	
	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	
	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	
.. saving dense-layer-0 parameter .. done ..
dense-layer-0load_parameter
.. loaded dense-layer-0 pretrain parameter..
**layer1-weights	: (192) 	.n: 1, .c: 1, .h: 24, .w: 8	(h:0x17a3580, d:0x7fdb1c600a00)
<---- batch [0] ----->
	0.497185	0.432557	-0.371876	0.499041	-0.263911	-0.103419	-0.112089	0.169746	0.435539	0.346311	-0.186726	0.024548	-0.056547	-0.270423	0.034414	0.413962	
	-0.042795	-0.069301	0.439128	0.278389	0.215971	0.302758	-0.407199	0.018153	0.365020	0.329147	0.329603	-0.226950	-0.440757	0.170528	0.093066	0.171654	
	-0.088212	-0.302449	-0.210370	-0.357880	0.283314	-0.087461	-0.465829	0.124030	0.160636	-0.201505	-0.053865	-0.277875	-0.426636	-0.030761	-0.403828	0.403370	
	-0.380510	0.024799	-0.416377	0.416861	0.410448	-0.201070	0.084389	0.065912	0.113938	0.456536	-0.239021	-0.268985	0.033448	0.449938	-0.006940	0.040601	
<---- batch [1] ----->
	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	
	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.363281	0.329147	0.000000	0.000000	
	-nan	-nan	0.093066	0.171654	0.000000	0.000000	0.000000	0.000000	0.283314	-0.087461	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	
	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	
<---- batch [2] ----->
	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	
	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	
	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	
	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	
<---- batch [3] ----->
	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	
	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	
	0.000000	0.000000	88.491150	0.000000	-nan	0.000000	0.000000	0.000003	2199027187712.000000	-885443715538058477568.000000	0.000000	536903680.000000	-127626393111461215637564088457963241472.000000	0.000000	0.000000	2424274944.000000	
	0.000000	49542447759360000.000000	0.000000	0.000048	-127626393111461215637564088457963241472.000000	0.000000	0.000000	0.000040	0.000000	37879808.000000	0.000000	37756928.000000	-811448728142151374067969824915456.000000	0.000000	0.000000	-32824753854176411351622090752.000000	
**layer1-biases	: (8) 	.n: 1, .c: 1, .h: 8, .w: 1	(h:0x17a3890, d:0x7fdb1c600e00)
<---- batch [0] ----->
	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	
<---- batch [1] ----->
	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	
<---- batch [2] ----->
	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	0.000000	
<---- batch [3] ----->
	0.363281	0.329147	0.000000	0.000000	-nan	-nan	0.093066	0.171654	
[       OK ] Testlayer.DenseInitWeightBias (1 ms)
[ RUN      ] Testlayer.DenseLayerForward
**input_dataset	: (24) 	.n: 1, .c: 2, .h: 3, .w: 4	(h:0x17a3b10, d:0)
	0.5	0.549917	0.599335	0.64776	
	0.694709	0.739713	0.782321	0.822109	
	0.858678	0.891663	0.920735	0.945604	
	0.96602	0.981779	0.992725	0.998747	
	0.999787	0.995832	0.986924	0.97315	
	0.954649	0.931605	0.904248	0.872853	
.. initialized dense-layer-0 layer ..
invoke forward func
88.4911
4.58659e-41
88.4911
4.58659e-41
[       OK ] Testlayer.DenseLayerForward (1214 ms)
[ RUN      ] Testlayer.DenseLayerBackwardInit
**grad_output	: (24) 	.n: 1, .c: 2, .h: 3, .w: 4	(h:0x1efe8950, d:0)
	0.5	0.549917	0.599335	0.64776	
	0.694709	0.739713	0.782321	0.822109	
	0.858678	0.891663	0.920735	0.945604	
	0.96602	0.981779	0.992725	0.998747	
	0.999787	0.995832	0.986924	0.97315	
	0.954649	0.931605	0.904248	0.872853	
**input	: (24) 	.n: 1, .c: 2, .h: 3, .w: 4	(h:0x1f350d70, d:0)
	0.5	0.549917	0.599335	0.64776	
	0.694709	0.739713	0.782321	0.822109	
	0.858678	0.891663	0.920735	0.945604	
	0.96602	0.981779	0.992725	0.998747	
	0.999787	0.995832	0.986924	0.97315	
	0.954649	0.931605	0.904248	0.872853	
.. initialized dense-layer layer ..
Print Gradient Input 
**gradient input data	: (24) 	.n: 1, .c: 2, .h: 3, .w: 4	(h:0x1effa6e0, d:0x7fdb1c62d800)
	0	0	2.5757e-40	0	
	2.70682e-20	0	2.70682e-20	0	
	0	0	0	0	
	4.57205e-38	0	0	0	
	7.17465e-43	0	4.57205e-38	0	
	0	0	0	0	
[       OK ] Testlayer.DenseLayerBackwardInit (1 ms)
[----------] 3 tests from Testlayer (1217 ms total)

[----------] Global test environment tear-down
[==========] 6 tests from 2 test suites ran. (1695 ms total)
[  PASSED  ] 6 tests.
